{"level":"info","message":"Starting clinical data analysis request","timestamp":"2025-09-22T10:40:54.801Z"}
{"level":"info","message":"Clinical data analysis completed","timestamp":"2025-09-22T10:40:54.803Z"}
{"level":"info","message":"Starting multimodal analysis request","timestamp":"2025-09-28T10:22:55.527Z"}
{"level":"error","message":"Multimodal analysis failed: Multimodal input validation failed: Voice data must include audio file or buffer","stack":"Error: Multimodal input validation failed: Voice data must include audio file or buffer\n    at MultimodalProcessorManager.processMultimodalInput (/app/src/processors/multimodal-manager.js:87:23)\n    at process.processTicksAndRejections (node:internal/process/task_queues:105:5)\n    at async /app/src/api/routes/multimodal.js:94:33","timestamp":"2025-09-28T10:22:55.529Z"}
{"level":"info","message":"Starting multimodal analysis request","timestamp":"2025-09-28T10:38:05.629Z"}
{"level":"info","message":"Request files:","timestamp":"2025-09-28T10:38:05.630Z"}
{"0":"voice_duration","1":"image_type","2":"clinical_data","level":"info","message":"Request body keys:","timestamp":"2025-09-28T10:38:05.630Z"}
{"level":"error","message":"Multimodal analysis failed: Multimodal input validation failed: Voice data must include audio file or buffer","stack":"Error: Multimodal input validation failed: Voice data must include audio file or buffer\n    at MultimodalProcessorManager.processMultimodalInput (/app/src/processors/multimodal-manager.js:87:23)\n    at process.processTicksAndRejections (node:internal/process/task_queues:105:5)\n    at async /app/src/api/routes/multimodal.js:98:33","timestamp":"2025-09-28T10:38:05.632Z"}
{"level":"info","message":"Starting multimodal analysis request","timestamp":"2025-09-28T10:44:34.955Z"}
{"level":"error","message":"Multimodal analysis failed: Audio validation failed: Sample rate must be at least 44100 Hz, Bit depth must be at least 16 bits","stack":"Error: Audio validation failed: Sample rate must be at least 44100 Hz, Bit depth must be at least 16 bits\n    at AudioProcessor.process (/app/src/processors/audio-processor.js:59:23)\n    at process.processTicksAndRejections (node:internal/process/task_queues:105:5)\n    at async MultimodalProcessorManager.processVoiceData (/app/src/processors/multimodal-manager.js:201:28)\n    at async Promise.all (index 0)\n    at async MultimodalProcessorManager.processMultimodalInput (/app/src/processors/multimodal-manager.js:122:13)\n    at async /app/src/api/routes/multimodal.js:94:33","timestamp":"2025-09-28T10:44:34.961Z"}
{"level":"info","message":"Starting multimodal analysis request","timestamp":"2025-09-28T10:48:14.503Z"}
{"level":"info","message":"Multimodal analysis completed for analysis_id: analysis_1759056494512_vi3nx8sud","timestamp":"2025-09-28T10:48:14.513Z"}
{"level":"info","message":"Starting multimodal analysis request","timestamp":"2025-09-30T20:57:46.747Z"}
{"level":"error","message":"Multimodal analysis failed: Medical agent not initialized","stack":"Error: Medical agent not initialized\n    at TENFrameworkManager.generateConversationResponse (/app/src/ten-framework/ten-manager.js:419:23)\n    at /app/src/api/routes/multimodal.js:98:55\n    at process.processTicksAndRejections (node:internal/process/task_queues:105:5)","timestamp":"2025-09-30T20:57:46.755Z"}
{"level":"info","message":"Starting multimodal analysis request","timestamp":"2025-09-30T21:04:14.638Z"}
{"level":"error","message":"Multimodal analysis failed: Medical agent not initialized","stack":"Error: Medical agent not initialized\n    at TENFrameworkManager.generateConversationResponse (/app/src/ten-framework/ten-manager.js:419:23)\n    at /app/src/api/routes/multimodal.js:98:55\n    at process.processTicksAndRejections (node:internal/process/task_queues:105:5)","timestamp":"2025-09-30T21:04:14.644Z"}
{"level":"info","message":"Starting multimodal analysis request","timestamp":"2025-09-30T21:07:44.478Z"}
{"level":"info","message":"Multimodal analysis completed for analysis_id: analysis_1759266464484_nmp4q0uyv","timestamp":"2025-09-30T21:07:44.486Z"}
{"level":"info","message":"Starting multimodal analysis request","timestamp":"2025-09-30T21:08:43.071Z"}
{"level":"info","message":"Multimodal analysis completed for analysis_id: analysis_1759266523076_u1p0k8jue","timestamp":"2025-09-30T21:08:43.077Z"}
{"level":"info","message":"Starting multimodal analysis request","timestamp":"2025-09-30T21:22:24.170Z"}
{"level":"info","message":"Multimodal analysis completed for analysis_id: analysis_1759267344176_cd09y0q6g","timestamp":"2025-09-30T21:22:24.177Z"}
{"level":"info","message":"Starting multimodal analysis request","timestamp":"2025-09-30T21:26:26.325Z"}
{"level":"info","message":"Multimodal analysis completed for analysis_id: analysis_1759267586331_rb96bi3yr","timestamp":"2025-09-30T21:26:26.337Z"}
{"level":"info","message":"Starting multimodal analysis request","timestamp":"2025-09-30T21:27:40.355Z"}
{"level":"info","message":"Multimodal analysis completed for analysis_id: analysis_1759267660360_9ydnxf271","timestamp":"2025-09-30T21:27:40.366Z"}
{"level":"info","message":"Starting multimodal analysis request","timestamp":"2025-09-30T21:31:05.167Z"}
{"level":"info","message":"Multimodal analysis completed for analysis_id: analysis_1759267865172_zqs8qzeww","timestamp":"2025-09-30T21:31:05.177Z"}
{"level":"info","message":"Starting multimodal analysis request","timestamp":"2025-09-30T21:32:17.484Z"}
{"level":"info","message":"Multimodal analysis completed for analysis_id: analysis_1759267937489_6zpo0l5k5","timestamp":"2025-09-30T21:32:17.494Z"}
{"level":"info","message":"Starting voice analysis request","timestamp":"2025-09-30T21:37:16.421Z"}
{"level":"info","message":"Voice analysis completed","timestamp":"2025-09-30T21:37:16.425Z"}
{"level":"info","message":"Starting multimodal analysis request","timestamp":"2025-09-30T21:37:54.600Z"}
{"level":"info","message":"Multimodal analysis completed for analysis_id: analysis_1759268274608_93gen0od7","timestamp":"2025-09-30T21:37:54.614Z"}
{"level":"info","message":"Starting voice analysis request","timestamp":"2025-09-30T21:59:24.450Z"}
{"level":"info","message":"Voice analysis completed","timestamp":"2025-09-30T21:59:24.451Z"}
{"level":"info","message":"Starting voice analysis request","timestamp":"2025-09-30T22:10:21.061Z"}
{"level":"info","message":"Voice analysis completed","timestamp":"2025-09-30T22:10:21.063Z"}
{"level":"info","message":"Starting voice analysis request","timestamp":"2025-09-30T22:21:11.826Z"}
{"level":"error","message":"Voice analysis failed: Invalid WAV file","stack":"TypeError: Invalid WAV file\n    at Object.decode (/app/node_modules/node-wav/index.js:189:11)\n    at AudioProcessor.loadAudioFile (/app/src/processors/audio-processor.js:83:35)\n    at AudioProcessor.processAudio (/app/src/processors/audio-processor.js:42:42)\n    at MultimodalProcessorManager.processVoiceData (/app/src/processors/multimodal-manager.js:201:54)\n    at /app/src/api/routes/multimodal.js:163:54\n    at Layer.handle [as handle_request] (/app/node_modules/express/lib/router/layer.js:95:5)\n    at next (/app/node_modules/express/lib/router/route.js:149:13)\n    at done (/app/node_modules/multer/lib/make-middleware.js:47:7)\n    at indicateDone (/app/node_modules/multer/lib/make-middleware.js:51:68)\n    at /app/node_modules/multer/lib/make-middleware.js:157:11","timestamp":"2025-09-30T22:21:11.828Z"}
{"level":"info","message":"Starting voice analysis request","timestamp":"2025-09-30T22:22:08.305Z"}
{"level":"error","message":"Voice analysis failed: fft.fft is not a function","stack":"TypeError: fft.fft is not a function\n    at AudioProcessor.calculateHNR (/app/src/processors/audio-processor.js:281:34)\n    at AudioProcessor.extractRealAcousticFeatures (/app/src/processors/audio-processor.js:152:30)\n    at AudioProcessor.processAudio (/app/src/processors/audio-processor.js:45:49)\n    at process.processTicksAndRejections (node:internal/process/task_queues:105:5)\n    at async MultimodalProcessorManager.processVoiceData (/app/src/processors/multimodal-manager.js:201:28)\n    at async /app/src/api/routes/multimodal.js:163:30","timestamp":"2025-09-30T22:22:09.656Z"}
{"level":"info","message":"Starting voice analysis request","timestamp":"2025-09-30T22:24:19.871Z"}
{"level":"info","message":"Voice analysis completed","timestamp":"2025-09-30T22:24:21.231Z"}
{"level":"info","message":"Starting voice analysis request","timestamp":"2025-09-30T22:24:49.119Z"}
{"level":"info","message":"Voice analysis completed","timestamp":"2025-09-30T22:24:50.471Z"}
{"level":"info","message":"Starting voice analysis request","timestamp":"2025-09-30T22:24:57.707Z"}
{"level":"info","message":"Voice analysis completed","timestamp":"2025-09-30T22:24:59.042Z"}
{"level":"info","message":"Starting multimodal analysis request","timestamp":"2025-09-30T22:25:09.108Z"}
{"level":"info","message":"Multimodal analysis completed for analysis_id: analysis_1759271109113_3k6aqlokk","timestamp":"2025-09-30T22:25:09.119Z"}
{"level":"info","message":"Starting multimodal analysis request","timestamp":"2025-09-30T22:31:44.905Z"}
{"headers":{"alt-svc":"h3=\":443\"; ma=86400","cf-cache-status":"DYNAMIC","cf-ray":"98772c19fa2b5fbc-SIN","connection":"keep-alive","content-length":"15","content-type":"application/json; charset=utf-8","date":"Tue, 30 Sep 2025 22:31:45 GMT","nel":"{\"report_to\":\"cf-nel\",\"success_fraction\":0.0,\"max_age\":604800}","report-to":"{\"group\":\"cf-nel\",\"max_age\":604800,\"endpoints\":[{\"url\":\"https://a.nel.cloudflare.com/report/v4?s=UnvAA%2FNIorikqN85S4z1Ic01WgchMqZ4Qh2zAgqZEun2jdQxOvPk1LRqXInzFDbJkfgqNJ6S8vcZQKS3tEoyUORdho0cXP5qjBSZ2ol0oyme\"}]}","server":"cloudflare"},"level":"error","message":"Multimodal analysis failed: 401 status code (no body)","stack":"Error: 401 status code (no body)\n    at APIError.generate (/app/node_modules/openai/error.js:48:20)\n    at OpenAI.makeStatusError (/app/node_modules/openai/core.js:302:33)\n    at OpenAI.makeRequest (/app/node_modules/openai/core.js:346:30)\n    at process.processTicksAndRejections (node:internal/process/task_queues:105:5)\n    at async AIAnalysisService.analyzeVoiceForTumorDiagnosis (/app/src/services/ai-analysis-service.js:39:30)\n    at async MultimodalProcessorManager.performMultimodalFusion (/app/src/processors/multimodal-manager.js:247:32)\n    at async MultimodalProcessorManager.processMultimodalInput (/app/src/processors/multimodal-manager.js:127:34)\n    at async /app/src/api/routes/multimodal.js:96:33","status":401,"timestamp":"2025-09-30T22:31:45.542Z"}
{"level":"info","message":"Starting multimodal analysis request","timestamp":"2025-09-30T22:33:03.192Z"}
{"headers":{"alt-svc":"h3=\":443\"; ma=86400","cf-cache-status":"DYNAMIC","cf-ray":"98772e034948919b-SIN","connection":"keep-alive","content-length":"87","content-type":"application/json; charset=utf-8","date":"Tue, 30 Sep 2025 22:33:03 GMT","nel":"{\"report_to\":\"cf-nel\",\"success_fraction\":0.0,\"max_age\":604800}","report-to":"{\"group\":\"cf-nel\",\"max_age\":604800,\"endpoints\":[{\"url\":\"https://a.nel.cloudflare.com/report/v4?s=EW3jeAsoObKH2yfHDxreEYQeR7EUWupeXsofxlF2A0T8j6hV3Vj%2BzsoyXnwO4wSAJ4ZuLSg%2BHY6Ciftp6BAEn5LJHL7NbSRHobDq7Y6L%2B8BI0%2Bg%3D\"}]}","server":"cloudflare"},"level":"error","message":"Multimodal analysis failed: 400 status code (no body)","stack":"Error: 400 status code (no body)\n    at APIError.generate (/app/node_modules/openai/error.js:45:20)\n    at OpenAI.makeStatusError (/app/node_modules/openai/core.js:302:33)\n    at OpenAI.makeRequest (/app/node_modules/openai/core.js:346:30)\n    at process.processTicksAndRejections (node:internal/process/task_queues:105:5)\n    at async AIAnalysisService.analyzeVoiceForTumorDiagnosis (/app/src/services/ai-analysis-service.js:39:30)\n    at async MultimodalProcessorManager.performMultimodalFusion (/app/src/processors/multimodal-manager.js:247:32)\n    at async MultimodalProcessorManager.processMultimodalInput (/app/src/processors/multimodal-manager.js:127:34)\n    at async /app/src/api/routes/multimodal.js:96:33","status":400,"timestamp":"2025-09-30T22:33:03.513Z"}
{"level":"info","message":"Starting multimodal analysis request","timestamp":"2025-09-30T22:36:21.789Z"}
{"headers":{"alt-svc":"h3=\":443\"; ma=86400","cf-cache-status":"DYNAMIC","cf-ray":"987732dc7f6e1d6d-SIN","connection":"keep-alive","content-length":"87","content-type":"application/json; charset=utf-8","date":"Tue, 30 Sep 2025 22:36:22 GMT","nel":"{\"report_to\":\"cf-nel\",\"success_fraction\":0.0,\"max_age\":604800}","report-to":"{\"group\":\"cf-nel\",\"max_age\":604800,\"endpoints\":[{\"url\":\"https://a.nel.cloudflare.com/report/v4?s=S%2F9r55gni4zWHeEfcjZQsjY1PNAE0iBvHu3X2W2N57z%2FGnr79XbAy7gTsCXCSXhlLc3cYs2vu11aBPaF2mhnDQ5HEqpYizeYWPfaw%2FfJwpmHXGQ%3D\"}]}","server":"cloudflare"},"level":"error","message":"Multimodal analysis failed: 400 status code (no body)","stack":"Error: 400 status code (no body)\n    at APIError.generate (/app/node_modules/openai/error.js:45:20)\n    at OpenAI.makeStatusError (/app/node_modules/openai/core.js:302:33)\n    at OpenAI.makeRequest (/app/node_modules/openai/core.js:346:30)\n    at process.processTicksAndRejections (node:internal/process/task_queues:105:5)\n    at async AIAnalysisService.analyzeVoiceForTumorDiagnosis (/app/src/services/ai-analysis-service.js:42:30)\n    at async MultimodalProcessorManager.performMultimodalFusion (/app/src/processors/multimodal-manager.js:247:32)\n    at async MultimodalProcessorManager.processMultimodalInput (/app/src/processors/multimodal-manager.js:127:34)\n    at async /app/src/api/routes/multimodal.js:96:33","status":400,"timestamp":"2025-09-30T22:36:22.160Z"}
{"level":"info","message":"Starting multimodal analysis request","timestamp":"2025-09-30T22:39:12.462Z"}
{"level":"info","message":"Multimodal analysis completed for analysis_id: analysis_1759271952772_cmq6vz4ll","timestamp":"2025-09-30T22:39:13.045Z"}
{"level":"info","message":"Starting multimodal analysis request","timestamp":"2025-09-30T22:39:31.183Z"}
{"level":"info","message":"Multimodal analysis completed for analysis_id: analysis_1759271971695_ap4ganvze","timestamp":"2025-09-30T22:39:31.953Z"}
{"level":"info","message":"Starting multimodal analysis request","timestamp":"2025-09-30T22:41:49.183Z"}
{"level":"info","message":"Multimodal analysis completed for analysis_id: analysis_1759272109486_0konmau3o","timestamp":"2025-09-30T22:41:49.761Z"}
{"level":"info","message":"Starting multimodal analysis request","timestamp":"2025-09-30T22:43:18.487Z"}
{"level":"info","message":"Multimodal analysis completed for analysis_id: analysis_1759272223356_rhpfr5bg9","timestamp":"2025-09-30T22:43:56.547Z"}
{"level":"info","message":"Starting multimodal analysis request","timestamp":"2025-09-30T22:44:18.703Z"}
{"level":"info","message":"Multimodal analysis completed for analysis_id: analysis_1759272275056_2qytelm1d","timestamp":"2025-09-30T22:44:46.766Z"}
{"level":"info","message":"Starting multimodal analysis request","timestamp":"2025-09-30T22:45:32.066Z"}
{"level":"info","message":"Multimodal analysis completed for analysis_id: analysis_1759272348244_t4dsxu3nf","timestamp":"2025-09-30T22:46:04.890Z"}
{"level":"info","message":"Starting multimodal analysis request","timestamp":"2025-09-30T22:46:35.421Z"}
{"level":"info","message":"Multimodal analysis completed for analysis_id: analysis_1759272421114_6evqtelto","timestamp":"2025-09-30T22:47:10.831Z"}
{"level":"info","message":"Starting multimodal analysis request","timestamp":"2025-09-30T22:51:17.385Z"}
{"level":"error","message":"Multimodal analysis failed: Cannot read properties of undefined (reading 'detected')","stack":"TypeError: Cannot read properties of undefined (reading 'detected')\n    at MultimodalProcessorManager.extractRiskFromVoice (/app/src/processors/multimodal-manager.js:482:63)\n    at MultimodalProcessorManager.fuseFeatures (/app/src/processors/multimodal-manager.js:442:61)\n    at MultimodalProcessorManager.performMultimodalFusion (/app/src/processors/multimodal-manager.js:272:38)\n    at process.processTicksAndRejections (node:internal/process/task_queues:105:5)\n    at async MultimodalProcessorManager.processMultimodalInput (/app/src/processors/multimodal-manager.js:127:34)\n    at async /app/src/api/routes/multimodal.js:96:33","timestamp":"2025-09-30T22:51:42.684Z"}
{"level":"info","message":"Starting multimodal analysis request","timestamp":"2025-09-30T22:59:21.987Z"}
{"level":"info","message":"Multimodal analysis completed for analysis_id: analysis_1759273182606_73y9mw67b","timestamp":"2025-09-30T22:59:55.150Z"}
{"level":"info","message":"Starting multimodal analysis request","timestamp":"2025-09-30T23:00:19.101Z"}
{"level":"error","message":"Multimodal analysis failed: Cannot read properties of undefined (reading 'detected')","stack":"TypeError: Cannot read properties of undefined (reading 'detected')\n    at MultimodalProcessorManager.extractRiskFromVoice (/app/src/processors/multimodal-manager.js:482:63)\n    at MultimodalProcessorManager.fuseFeatures (/app/src/processors/multimodal-manager.js:442:61)\n    at MultimodalProcessorManager.performMultimodalFusion (/app/src/processors/multimodal-manager.js:272:38)\n    at process.processTicksAndRejections (node:internal/process/task_queues:105:5)\n    at async MultimodalProcessorManager.processMultimodalInput (/app/src/processors/multimodal-manager.js:127:34)\n    at async /app/src/api/routes/multimodal.js:96:33","timestamp":"2025-09-30T23:00:55.914Z"}
{"level":"info","message":"Starting multimodal analysis request","timestamp":"2025-09-30T23:01:12.700Z"}
{"level":"info","message":"Multimodal analysis completed for analysis_id: analysis_1759273291944_dsqwzdafj","timestamp":"2025-09-30T23:01:47.182Z"}
{"level":"info","message":"Starting multimodal analysis request","timestamp":"2025-09-30T23:03:04.951Z"}
{"level":"info","message":"Multimodal analysis completed for analysis_id: analysis_1759273423205_o82ujgjcd","timestamp":"2025-09-30T23:04:18.737Z"}
{"level":"info","message":"Starting multimodal analysis request","timestamp":"2025-09-30T23:04:52.728Z"}
{"level":"info","message":"Multimodal analysis completed for analysis_id: analysis_1759273518700_f3o2q788h","timestamp":"2025-09-30T23:05:20.631Z"}
{"level":"info","message":"Starting multimodal analysis request","timestamp":"2025-09-30T23:07:03.744Z"}
{"level":"info","message":"Starting multimodal analysis request","timestamp":"2025-09-30T23:08:19.400Z"}
{"level":"info","message":"Multimodal analysis completed for analysis_id: analysis_1759273704170_43bfnh5dw","timestamp":"2025-09-30T23:08:26.126Z"}
{"level":"info","message":"Multimodal analysis completed for analysis_id: analysis_1759273754201_67p7gcqzn","timestamp":"2025-09-30T23:09:16.454Z"}
{"level":"info","message":"Starting multimodal analysis request","timestamp":"2025-09-30T23:16:12.128Z"}
{"level":"info","message":"Multimodal analysis completed for analysis_id: analysis_1759274204266_v80zr0xwc","timestamp":"2025-09-30T23:16:46.339Z"}
{"level":"info","message":"Starting multimodal analysis request","timestamp":"2025-09-30T23:18:14.142Z"}
{"level":"info","message":"Multimodal analysis completed for analysis_id: analysis_1759274328931_e6sf9lie8","timestamp":"2025-09-30T23:18:50.556Z"}
{"level":"info","message":"Starting multimodal analysis request","timestamp":"2025-09-30T23:19:47.353Z"}
{"level":"info","message":"Multimodal analysis completed for analysis_id: analysis_1759274413250_lvp2wvk2d","timestamp":"2025-09-30T23:20:14.606Z"}
{"level":"info","message":"Starting multimodal analysis request","timestamp":"2025-10-01T06:06:16.386Z"}
{"level":"info","message":"Multimodal analysis completed for analysis_id: analysis_1759298796172_w817kylez","timestamp":"2025-10-01T06:06:46.008Z"}
